import os
import fitz  # PyMuPDF
import openai
import tiktoken
from pinecone import Pinecone

# â–¼ APIã‚­ãƒ¼ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼ˆç›´æ¥æ›¸ã„ã¦ã‚‚å¯ï¼‰
openai.api_key = os.getenv("OPENAI_API_KEY")
pinecone_api_key = os.getenv("PINECONE_API_KEY")

# â–¼ Pinecone v3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
pc = Pinecone(api_key=pinecone_api_key)

# â–¼ æ¥ç¶šã™ã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åï¼ˆäº‹å‰ã«ä½œæˆæ¸ˆã¿ã§ã‚ã‚‹ã“ã¨ï¼‰
index = pc.Index("urata-soft")

# â–¼ ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã§åˆ†å‰²ï¼ˆ500ãƒˆãƒ¼ã‚¯ãƒ³å‰å¾Œï¼‰
def split_text(text, max_tokens=500):
    encoding = tiktoken.get_encoding("cl100k_base")
    lines = text.split("\n")
    chunks, current = [], ""
    for line in lines:
        test = current + "\n" + line
        if len(encoding.encode(test)) <= max_tokens:
            current = test
        else:
            chunks.append(current.strip())
            current = line
    if current:
        chunks.append(current.strip())
    return chunks

# â–¼ PDFèª­ã¿è¾¼ã¿â†’EmbeddingåŒ–â†’Pineconeã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
def process_pdf(pdf_path, namespace="nextgen-specs"):
    print(f"\nğŸ“„ å‡¦ç†é–‹å§‹: {pdf_path}")
    doc = fitz.open(pdf_path)
    full_text = ""
    for page in doc:
        full_text += page.get_text()
    doc.close()

    chunks = split_text(full_text)

    for i, chunk in enumerate(chunks):
        embedding = openai.embeddings.create(
            input=chunk,
            model="text-embedding-3-small"
        ).data[0].embedding

        index.upsert(
            vectors=[{
                "id": f"{os.path.basename(pdf_path)}-chunk-{i}",
                "values": embedding,
                "metadata": {"text": chunk}
            }],
            namespace=namespace
        )
        print(f"âœ… {pdf_path} â†’ chunk {i} ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†")

# â–¼ å¯¾è±¡ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã“ã“ã«åˆ—æŒ™ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã‚’æ­£ç¢ºã«ï¼‰
pdf_files = [
    "./PDF/ourCo.pdf"
]

# â–¼ å®Ÿè¡Œ
for file in pdf_files:
    process_pdf(file)
